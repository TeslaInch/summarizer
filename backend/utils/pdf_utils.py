# utils/pdf_utils.py
import fitz  # PyMuPDF
import pikepdf
from io import BytesIO
import logging
from collections import Counter

logger = logging.getLogger(__name__)

# Scanner-related keywords (full words only, not substrings)
SCANNER_TERMS = {
    'camscanner', 'scanbot', 'adobe scan', 'microsoft lens',
    'tiny scanner', 'mobilepdf', 'pdf now', 'document scanner',
    'scanned by', 'created by', 'converted by', 'generated by'
}

JUNK_PHRASES = {
    'this is a scanned copy', 'no text available', 'please check original',
    'image only', 'cannot extract text', 'do not print', 'draft',
    'confidential', 'unauthorized', 'copy'
}

def is_junk_text(text: str) -> bool:
    """Detect if text is meaningless (scanner watermark, repetition, etc.)"""
    if not text or len(text.strip()) < 10:
        return True

    text_lower = text.lower().strip()

    # ✅ 1. Check for junk phrases
    if any(phrase in text_lower for phrase in JUNK_PHRASES):
        return True

    # ✅ 2. Check for scanner terms (exact word boundaries)
    words = text_lower.split()
    scanner_count = 0
    total_relevant_words = 0

    for word in words:
        cleaned = word.strip('.,:;()[]{}"\'')
        if len(cleaned) <= 2:
            continue
        total_relevant_words += 1
        # Only match full scanner terms
        if cleaned in SCANNER_TERMS:
            scanner_count += 1

    # If > 30% of meaningful words are scanner terms → likely junk
    if total_relevant_words > 5 and scanner_count / total_relevant_words > 0.3:
        return True

    # ✅ 3. High repetition? (only if meaningful words are few)
    if len(words) > 20:
        freq = Counter(words)
        unique_ratio = len(freq) / len(words)
        if unique_ratio < 0.3:  # Less than 30% unique words
            return True

    return False

def extract_text_from_pdf(content: bytes) -> str:
    """
    Extract text from a native PDF.
    Rejects scanned, low-content, or junk-filled PDFs.
    """
    # Validate PDF structure
    try:
        with pikepdf.Pdf.open(BytesIO(content)) as pdf:
            pass
    except Exception as e:
        logger.warning(f"PDF validation failed: {e}")
        return "Invalid or scanned PDF: Could not validate PDF structure."

    try:
        doc = fitz.open(stream=content, filetype="pdf")
        all_text = []

        for page_num in range(doc.page_count):
            page = doc[page_num]
            text = page.get_text().strip()

            if not text:
                continue

            # Only reject if this page is *mostly* junk
            if is_junk_text(text):
                # But allow if it's just a small footer
                word_count = len(text.split())
                scanner_density = sum(1 for w in text.lower().split() if w in SCANNER_TERMS)
                if scanner_density > 2 and scanner_density / word_count > 0.5:
                    doc.close()
                    return "Scanned PDFs are not supported. Please upload a text-based PDF."
                # Otherwise, it's just a watermark — keep the text
                # (don't return, just skip rejection)

            all_text.append(text)

        doc.close()

        full_text = "\n\n".join(all_text).strip()

        if not full_text:
            return "No readable text found in PDF. The file may be scanned or corrupted."

        # Final: is the full document junk?
        if is_junk_text(full_text):
            return "Scanned PDFs are not supported. Please upload a text-based PDF."

        # ✅ Minimum meaningful content
        meaningful_words = [
            w.strip('.,:;()') for w in full_text.split()
            if len(w.strip('.,:;()')) > 2 and w.lower() not in SCANNER_TERMS
        ]
        if len(meaningful_words) < 50:
            return (
                "Document too short or low-quality. "
                "Please upload a more detailed text-based PDF with meaningful content."
            )

        return full_text

    except Exception as e:
        logger.error(f"Text extraction failed: {e}")
        return "Could not extract text from PDF. The file may be corrupted."